{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dji53O40dPED"
   },
   "source": [
    "# 머신러닝\n",
    "\n",
    "- 수치를 예측하는 회귀, 카테고리를 예측하는 분류, 최적의 추천 등을 수행하는 소프트웨어로, 데이터를 보고 학습하여 점차 성능이 개선된다\n",
    "- 현재 인공지능을 구현하는 대표적인 방법이 머신러닝 기법이다\n",
    " - 인공지능을 구현하는 다른 방법으로 \"생각하는\" 컴퓨터를 만들거나, 언어를 문법적으로 이해하는 컴퓨터를 만드는 것, 또는 사람의 지식을 알고리즘이나 데이터로 구축하는 방법은 성공하지 못했다\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝 동작\n",
    "<img src=\"https://raw.githubusercontent.com/data-labs/image/main/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202020-12-29%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.08.38.png?raw=1\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 (X)\n",
    "- 훈련 (train) 데이터: 모델을 학습시키는데 사용하는 데이터\n",
    "- 검증 (validation) 데이터: 학습시킨 모델의 동작을 검증하는데 사용하는 데이터\n",
    "- 학습에 사용하는 데이터가 많을수록 예측, 추천 성능이 향상된다\n",
    " - 데이터 타입: 정형 데이터(테이블 데이터), 비정형 데이터(이미지, 텍스트, 센서 데이터 등)\n",
    "- 머신러닝 모델의 성능을 높이기 위해서는 원시(raw) 데이터로부터 적절한 학습 및 검증 데이터를 만드는 **데이터 전처리**가 반드시 필요하다\n",
    "\n",
    "### 머신러닝 모델\n",
    "- 입력 데이터(X)로부터 최적의 출력(y)을 얻는 소프트웨어\n",
    "- 최적의 출력이란 정답(label, target)을 잘 예측하는 것을 말한다\n",
    " - 최적의 출력을 얻기 위해서 모델을 구성하는 파라미터의 최적치를 찾는다(예: 선형 회귀에서 가중치 값)\n",
    "- 모델의 종류: 선형모델, 로지스틱 회귀, SVM, 결정트리, 랜덤 포레스트, kNN, 베이시언, 딥러닝 모델 (MLP, CNN, RNN 등)\n",
    "\n",
    "### 목적\n",
    "- 머신러닝의 목적은 다음 중 하나이다\n",
    " - 예측(predictive) 분석\n",
    "> 회귀 예측(regression): 수치를 예측  \n",
    "> 분류 예측(classification): 카테고리를 예측\n",
    " - 설명(descriptive)적 분석\n",
    " - 군집화(clustering)\n",
    " - 추천(recommendation)\n",
    " \n",
    "### 성능평가 (performance measure)\n",
    "- 모델이 원하는 동작을 잘 수행하는지를 평가하는 값으로, 주요 평가 척도는 다음과 같다\n",
    " - 회귀모델에서는 R-squared를 사용\n",
    " - 분류 모델에서는 정확도(accuracy), 정밀도(precision), 리콜(recall), f-1 점수, ROC-AUC 등을 사용 \n",
    " \n",
    "### 최적화기 (optimizer)\n",
    "- 학습을 통하여 모델 파라미터를 최적의 값으로 수렴시키는 알고리즘\n",
    "- 최적화 알고리즘으로는 경사하강법(GD: gradient descent)이 기본적으로 사용된다 \n",
    "\n",
    "### 손실함수 (loss function)\n",
    "- 최적화기는 손실함수를 최소화 하는 방향으로 동작한다\n",
    "- 즉, 손실함수는 최적화기의 동작이 잘 이루어지고 있는지를 모니터링하는 값이다\n",
    "- 손실함수로, 회귀 모델에서는 MSE(mean square error)를, 분류에서는 크로스 엔트로피(cross entrophy)를 주로 사용한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "frUj53G19etJ"
   },
   "source": [
    "# 타이타닉 생존자 예측 \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/data-labs/image/main/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-01-07%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.36.15.png?raw=1\" width=400 align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터\n",
    "- 타이타닉 탑승자 개인별 데이터를 보고 생존 여부를 예측하는 예제 데이터\n",
    "\n",
    "- Survival - 생존여부(타겟변수 y): 0 = No, 1 = Yes\n",
    "- Pclass - 티켓 등급: 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- Sex - 성별: male, female\n",
    "- Age - 나이\n",
    "- SibSp - 동승한 형제, 배우자 수\n",
    "- Parch - 부모와 자녀의 수\n",
    "- Ticket - 티켓 번호\n",
    "- Fare - 승선 요금\n",
    "- Cabin - 캐빈(객실) 번호\n",
    "- Embarked - 승선한 항구: C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5306,
     "status": "ok",
     "timestamp": 1580277952501,
     "user": {
      "displayName": "김화종",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCOtXjyLykQ_8l9Pq2rL3r5y110ynjRS1eb1EzpcQ=s64",
      "userId": "17353049580175403985"
     },
     "user_tz": -540
    },
    "id": "8B2q9YpA9etK",
    "outputId": "69adc8d6-edd3-4213-924c-f0b787ed72d7"
   },
   "outputs": [],
   "source": [
    "## 환경설정\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 맥에서 레티나 디스플레이 사용 설정\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "print(\"AA\")\n",
    "# 그림 크기와 폰트 설정\n",
    "matplotlib.rcParams['figure.figsize'] = (6,4)\n",
    "plt.rc('font', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 데이터 전처리 종류\n",
    "\n",
    "- 데이터 클리닝 - 결측치 처리, 틀린값 처리\n",
    "- 스케일링 - 여러 변수 값의 범위를 동등한 조건으로 맞추는 것: 표준 스케일링, min-max 스케일링\n",
    "- 이상치 처리 - 이상치 탐지 및 제거\n",
    "- 데이터 변환 - 로그 변환, 카테고리 인코딩 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 전처리 전과정 실행\n",
    "\n",
    "# 데이터 다운로드하기\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/StillWork/data/master/titanic_train.csv\")\n",
    "\n",
    "# 나이 결측치를 평균 나이로 대체 (대체한 것을 즉시 반영했다)\n",
    "df.Age.fillna(df.Age.mean(), inplace=True)\n",
    "\n",
    "# Embarked (항구명) 결측치가 있는 두 샘플은 삭제한다\n",
    "df = df[~df[\"Embarked\"].isnull()]\n",
    "\n",
    "# 사용하지 않을 컬럼 4개를 삭제한 데이터프레임을 만들고 백업한다\n",
    "df = df[df.columns.difference(['PassengerId','Name','Ticket','Cabin'])]\n",
    "\n",
    "# 선실등급, 성별, 항구명을 원핫 인코딩한다\n",
    "df = pd.get_dummies(df, columns=['Pclass','Sex','Embarked'])\n",
    "\n",
    "# 요금(Fare)은 로그를 취한 값을 사용한다\n",
    "df[\"Fare\"] = np.log(df.Fare +1)\n",
    "\n",
    "# 연속형 변수에 표준 스케일링을 적용한다\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df.loc[:][['Age','Fare','SibSp','Parch']] = scaler.fit_transform(df[['Age','Fare','SibSp','Parch']])\n",
    "\n",
    "# 데이터분석에 사용할 X와 y 얻기\n",
    "X = df[df.columns.difference(['Survived'])]\n",
    "y = df.Survived\n",
    "\n",
    "# X, y 확인하기\n",
    "print(y[:5])\n",
    "X[:5].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 분류 예측\n",
    "- 개인별 정보를 보고 이 사람의 생존 여부를 예측하는 선형 분류 모델을 만들어 보겠다\n",
    "- 분류에 대해서는 \"머신러닝\"에서 자세히 설명한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진 분류를 위한 결정 경계 (decision boundary)\n",
    "- 하나의 변수만 사용하는 경우 선형분류 결정 경계: $x_{1} > b$  \n",
    "- 두 개의 변수를 사용하는 경우 선형분류 결정 경계: $a_{1}x_{1}+a_{2}x_{2}+b >0$  \n",
    "     > $x_{2} > -$$a_{1}\\over a_{2}$ $x_{1} - $$b\\over{a_{2}}$\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/data-labs/image/main/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-01-09%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%205.19.06.png?raw=1\" width=550 align='left'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련 및 성능 측정\n",
    "\n",
    "\n",
    "- 목적 변수\n",
    " - 분류 예측 대상 데이터로서 여기서는 생존 여부 데이터인 Survived 컬럼의 값이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X와 y를 훈련 데이터와 검증 데이터로 나눈다 (디폴트 비율은 75%: 25%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8, shuffle=True)\n",
    "\n",
    "# 훈련 및 검증 데이터 갯수 확인\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/data-labs/image/main/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202020-12-29%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.45.47.png?raw=1\" width=300 align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 선형 분류 모델로 SGDClassifier를 사용\n",
    "\n",
    "# 모델 생성\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier()\n",
    "\n",
    "# 학습 데이터를 사용하여 학습을 수행한다\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터를 사용하여 모델의 성능을 확인한다 (정확도를 알려준다)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 특성이 얼마나 중요하게 반영되었는지를 본다\n",
    "\n",
    "W = pd.DataFrame(model.coef_[0].round(4), index=X.columns\n",
    "                , columns=['weight'])\n",
    "W.sort_values('weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 특성이 얼마나 중요하게 반영되었는지를 그래프로 보기\n",
    "\n",
    "W.sort_values('weight').plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 결과를 보면 생존하는데 가장 많이 기여한 변수는 여성, 요금, 1등석 등이고\n",
    "- 생존하지 않는데 가장 많이 기여한 변수는 남성, 나이, 3등객실 등인 것을 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "g_15_결정트리_타이타닉_캐글.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.675px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
